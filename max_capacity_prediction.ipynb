{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Maximum Battery Capacity from Cycling Data\n",
    "\n",
    "Noah H. Paulson, Saurabh Saxena\n",
    "\n",
    "Applied Materials Division\n",
    "\n",
    "Argonne National Laboratory\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This is an jupyter notebook intended to teach some of the basics\n",
    "of data analytics and data processing for the problem of predicting\n",
    "the maximum capacity of a Li-ion battery as a function of its\n",
    "voltage and current versus time signature for a particular cycle.\n",
    "\n",
    "We will be using cycling data described in the following publication:\n",
    "Severson, K.A., Attia, P.M., Jin, N. et al. Data-driven prediction of battery cycle life before capacity degradation. Nat Energy 4, 383â€“391 (2019). https://doi.org/10.1038/s41560-019-0356-8\n",
    "\n",
    "#### Download the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "url = 'https://drive.google.com/uc?export=download&id=1wcf5ctLG8TLnHN4lt3OJSpk5nmZcyY3z'\n",
    "output = 'Standford_Batch1_CH1.h5'\n",
    "gdown.download(url, output, quiet=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the initial modules and the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "fname = 'Standford_Batch1_CH1.h5'\n",
    "df = pd.read_hdf(fname)\n",
    "\n",
    "# print out the column headers\n",
    "print(df.keys())\n",
    "\n",
    "# how many cycles are there?\n",
    "ncycmax = df['Cycle Num'].max()\n",
    "print('\\nnumber of cycles:', ncycmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's plot some quantities we may be interested in\n",
    "Start off with current over the life of the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotting module\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# first plot the current over the entire life of the cell\n",
    "plt.figure(num='current_vs_cycle')\n",
    "plt.plot(df['Test Time (s)'].values, df['Current (Amps)'].values, 'k-')\n",
    "plt.xlabel('Test time (s)')\n",
    "plt.ylabel('Current (Amps)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gosh, that's really not helpful\n",
    "Let's look at cycles 1 through 3 cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = (df['Cycle Num'].values > 0)*(df['Cycle Num'].values < 4)\n",
    "\n",
    "plt.figure(num='current_vs_cycle_try2')\n",
    "plt.plot(df['Test Time (s)'].values[sel], df['Current (Amps)'].values[sel], 'k-')\n",
    "plt.xlabel('Test time (s)')\n",
    "plt.ylabel('Current (Amps)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are we looking at here?\n",
    "* positive current is for charging\n",
    "* negative current is for discharging\n",
    "* zero current is a rest\n",
    "\n",
    "#### On your own, plot the voltage versus time for cycle 1\n",
    "#### Take a few mintues to experiment with plotting other quantities as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### open up this cell if you need a hint\n",
    "<font color='white'>\n",
    "sel = df['Cycle Num'].values == 1\n",
    "plt.figure(num='voltage_cycle_1')\n",
    "plt.plot(df['Test Time (s)'].values[sel], df['Voltage'].values[sel], 'k-')\n",
    "plt.xlabel('Test time (s)')\n",
    "plt.ylabel('Voltage')\n",
    "plt.tight_layout()\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's extract the maximum discharge capacity of the cell throughout its life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycs = np.arange(2, ncycmax)\n",
    "cycs = np.delete(cycs, 10)\n",
    "Qmaxs = []\n",
    "\n",
    "plt.figure(num='discharge capacity vs. cycle')\n",
    "for cyc in cycs:\n",
    "    sel = (df['Cycle Num'].values == cyc)*(df['Current (Amps)'].values < -0.1)\n",
    "    t = df['Test Time (s)'].values[sel]\n",
    "    C = -1*df['Current (Amps)'].values[sel]\n",
    "    dt = np.diff(t)\n",
    "    Cmid = (C[1:] + C[:-1])/(2*3600)\n",
    "    Qmaxs.append(np.sum(dt*Cmid))\n",
    "\n",
    "    plt.plot(t - t.min(), C, 'k-', alpha=0.01)\n",
    "\n",
    "plt.xlabel('Test time (s)')\n",
    "plt.ylabel('Discharge current (Amps)')\n",
    "plt.tight_layout()\n",
    "    \n",
    "plt.figure(num='max capacity vs. cycle')\n",
    "plt.plot(cycs, Qmaxs, 'k-')\n",
    "plt.xlabel('Cycle number')\n",
    "plt.ylabel('Maximum capacity (Amp hrs.)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's extract some features that could help us predict the capacity\n",
    "\n",
    "Also, let's normalize them and plot them versus cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featd = {'mean V':[], 'V integral over time':[]}\n",
    "featd = {'cycles':[], 'mean V':[], 'V integral over time':[]}\n",
    "\n",
    "\n",
    "# calculate features for each cycles\n",
    "for cyc in cycs:\n",
    "    # select the cycle and where the current is negative\n",
    "    sel = (df['Cycle Num'].values == cyc)*(df['Current (Amps)'].values < -0.1)\n",
    "    t = df['Test Time (s)'].values[sel]\n",
    "    C = -1*df['Current (Amps)'].values[sel]\n",
    "    V = df['Voltage'].values[sel]\n",
    "\n",
    "    # calculate features\n",
    "    featd['cycles'].append(cyc)\n",
    "    featd['mean V'].append(V.mean())\n",
    "    dt = np.diff(t)\n",
    "    Vmid = (V[1:] + V[:-1])/2\n",
    "    featd['V integral over time'].append(np.sum(dt*Vmid))\n",
    "    \n",
    "# plot all of the features\n",
    "features = list(featd.keys())\n",
    "colors = sns.color_palette()[:len(features)]\n",
    "\n",
    "plt.figure(num='features vs. cycle')\n",
    "for feature, color in zip(features, colors):\n",
    "    feats = featd[feature]\n",
    "    # normalize the features\n",
    "    feats = (feats - np.mean(feats))/np.std(feats)\n",
    "    plt.plot(cycs, feats, marker='', ls='-',\n",
    "        c=color, alpha=0.9, label=feature)\n",
    "plt.xlabel('Cycle number')\n",
    "plt.ylabel('Normalized feature value')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before getting into machine learning let's split our dataset into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert feature dictionary into a Pandas dataframe because it is easier to handle\n",
    "fdf = pd.DataFrame.from_dict(featd)\n",
    "\n",
    "# reserve 100 cycles every 100 cycles for the test set\n",
    "indx_tst = np.arange(fdf.shape[0])\n",
    "indx_tst = np.mod(np.int32(indx_tst/100) - 1, 2) == 0\n",
    "indx_trnval = np.invert(indx_tst)\n",
    "\n",
    "X_ = fdf.values[indx_trnval, :]\n",
    "y = np.array(Qmaxs)\n",
    "y_ = y[indx_trnval]\n",
    "cycs_ = cycs[indx_trnval]\n",
    "indx = (np.random.random(size=X_.shape[0]) < 0.8)\n",
    "\n",
    "X_train = X_[indx, :]\n",
    "y_train = y_[indx]\n",
    "cycs_train = cycs_[indx]\n",
    "\n",
    "X_validate = X_[np.invert(indx), :]\n",
    "y_validate = y_[np.invert(indx)]\n",
    "cycs_validate = cycs_[np.invert(indx)]\n",
    "\n",
    "X_test = fdf.values[indx_tst, :]\n",
    "y_test = y[indx_tst]\n",
    "cycs_test = cycs[indx_tst]\n",
    "\n",
    "print('X_train.shape :', X_train.shape)\n",
    "print('X_validate.shape :', X_validate.shape)\n",
    "print('X_test.shape :', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's evaluate how these features correlate with the SOH\n",
    "We'll only do so for the training dataset as to no bias our decisions about which features to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "for feature in features:\n",
    "    feats = np.array(featd[feature])[indx_trnval][indx]\n",
    "    Qmaxs_ = np.array(Qmaxs)[indx_trnval][indx]\n",
    "\n",
    "    r, p = pearsonr(feats, Qmaxs_)\n",
    "    print(feature, 'pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "\n",
    "    plt.figure(num=feature + ' correlation')\n",
    "    plt.plot(Qmaxs_, feats, 'k.')\n",
    "    plt.plot([np.min(Qmaxs_), np.max(Qmaxs_)], [np.min(feats), np.max(feats)], 'k-')\n",
    "    plt.xlabel('Maximum capacity (Amp. hrs.)')\n",
    "    plt.ylabel(feature)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's finally develop a very simple machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a model using linear regression and evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "p_train = lr.predict(X_train)\n",
    "p_validate = lr.predict(X_validate)\n",
    "p_test = lr.predict(X_test)\n",
    "\n",
    "\n",
    "def cappred(y_train, p_train, y_validate, p_validate,\n",
    "            y_test=None, p_test=None, name=''):\n",
    "    r, p = pearsonr(y_train, p_train)\n",
    "    r, p = pearsonr(y_validate, p_validate)\n",
    "\n",
    "    r, p = pearsonr(y_train, p_train)\n",
    "    print('training pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "    r, p = pearsonr(y_validate, p_validate)\n",
    "    print('validation pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "    if p_test is not None:\n",
    "        r, p = pearsonr(y_test, p_test)\n",
    "        print('testing pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "\n",
    "    mae = np.mean(100*np.abs(y_train - p_train)/y_train)\n",
    "    print('training MAPE:', np.round(mae, 3), '%')\n",
    "    mae = np.mean(100*np.abs(y_validate - p_validate)/y_validate)\n",
    "    print('validation MAPE:', np.round(mae, 3), '%')\n",
    "    if p_test is not None:\n",
    "        mae = np.mean(100*np.abs(y_test - p_test)/y_test)\n",
    "        print('testing MAPE:', np.round(mae, 3), '%')\n",
    "\n",
    "    plt.figure(num=name + ' prediction')\n",
    "    plt.plot(cycs, y, 'g-', label='SOH')\n",
    "    plt.plot(cycs_train, p_train, 'k.', alpha=0.5, label='train')\n",
    "    plt.plot(cycs_validate, p_validate, 'b.', alpha=0.5, label='validate')\n",
    "    if p_test is not None:\n",
    "        plt.plot(cycs_test, p_test, 'r.', alpha=0.5, label='test')\n",
    "    plt.ylim(1.02, 1.08)\n",
    "    plt.xlabel('Cycle number')\n",
    "    plt.ylabel('Maximum capacity')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(num=name + ' parity', figsize=(4.5, 4))\n",
    "    plt.plot(y_train, p_train, 'k.', alpha=0.5, label='train')\n",
    "    plt.plot(y_validate, p_validate, 'b.', alpha=0.5, label='validate')\n",
    "    if p_test is not None:\n",
    "        plt.plot(y_test, p_test, 'r.', alpha=0.5, label='test')\n",
    "    plt.plot([1.02, 1.08], [1.02, 1.08], 'k-')\n",
    "    plt.xlim(1.02, 1.08)\n",
    "    plt.ylim(1.02, 1.08)\n",
    "    plt.xlabel('experiment')\n",
    "    plt.ylabel('prediction')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "cappred(y_train, p_train, y_validate, p_validate, y_test, p_test, 'lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take 15 or so minutes to experiment with different feature sets and see if you can improve the validation performance. As a hint, look at the voltage and current behavior and see if you can think of features that may correlate well with the SOH.\n",
    "\n",
    "Next, instead of using an analytical least squares regression approach as before, let's manually define our model and optimize the parameters numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "def lin_model(X, params):\n",
    "    p = params[0]*np.ones(X.shape[0])\n",
    "    for ii in range(X.shape[1]):\n",
    "        p += params[ii+1]*X[:, ii]\n",
    "    return p\n",
    "        \n",
    "def cost(X, y, params):\n",
    "    return np.sum((lin_model(X, params) - y)**2)\n",
    "\n",
    "def cost_opt(params):\n",
    "    return cost(X_train, y_train, params)\n",
    "\n",
    "nparam = X_train.shape[1] + 1\n",
    "params0 = np.zeros((nparam,))\n",
    "# res = minimize(cost_opt, params0)\n",
    "bounds = np.zeros((nparam, 2))\n",
    "bounds[:, 0] = -1\n",
    "bounds[:, 1] = 1\n",
    "res = differential_evolution(cost_opt, bounds)\n",
    "print(res)\n",
    "params = res.x\n",
    "\n",
    "p_train = lin_model(X_train, params)\n",
    "p_validate = lin_model(X_validate, params)\n",
    "p_test = lin_model(X_test, params)\n",
    "\n",
    "cappred(y_train, p_train, y_validate, p_validate, y_test, p_test, 'lr-opt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potentially more powerful machine learning techniques is Random Forest regression. It is effectively an ensemble of Decision Tree regressors that have been simultaneously trained with randomly generated subsamples of the dataset. We can start exploring the effect of hyperparameters through this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=2, criterion='mse', min_samples_split=50, min_samples_leaf=25).fit(X_train, y_train)\n",
    "p_train = rf.predict(X_train)\n",
    "p_validate = rf.predict(X_validate)\n",
    "p_test = rf.predict(X_test)\n",
    "\n",
    "cappred(y_train, p_train, y_validate, p_validate, y_test, p_test, 'rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's attempt to do a prediction with a neural network model. Here we are using the simplified Keras interface to Tensorflow, a powerful, production-grade software for deep learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "inputs = keras.Input(shape=(X_train.shape[1]), name='f_arr')\n",
    "x = keras.layers.Dense(4, activation='relu')(inputs)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='dense_pred')\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='MSE',\n",
    "              metrics=[])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=32,\n",
    "                    validation_data=(X_validate, y_validate))\n",
    "\n",
    "plt.figure(num='cost vs epoch')\n",
    "nhist = len(history.history['loss'])\n",
    "plt.semilogy(range(1, nhist+1), history.history['loss'],\n",
    "             'b-', label='training loss')\n",
    "plt.semilogy(range(1, nhist+1), history.history['val_loss'],\n",
    "             'r-', label='validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.tight_layout()\n",
    "\n",
    "p_train = np.squeeze(model.predict(X_train))\n",
    "p_validate = np.squeeze(model.predict(X_validate))\n",
    "p_test = np.squeeze(model.predict(X_test))             \n",
    "\n",
    "cappred(y_train, p_train, y_validate, p_validate, y_test, p_test, 'nn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
