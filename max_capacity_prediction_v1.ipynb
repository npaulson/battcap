{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Maximum Battery Capacity from Cycling Data\n",
    "\n",
    "Noah H. Paulson\n",
    "\n",
    "Applied Materials Division\n",
    "\n",
    "Argonne National Laboratory\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This is an jupyter notebook intended to teach some of the basics\n",
    "of data analytics and data processing for the problem of predicting\n",
    "the maximum capacity of a Li-ion battery as a function of its\n",
    "voltage and current versus time signature for a particular cycle.\n",
    "\n",
    "We will be using cycling data described in the following publication:\n",
    "Severson, K.A., Attia, P.M., Jin, N. et al. Data-driven prediction of battery cycle life before capacity degradation. Nat Energy 4, 383â€“391 (2019). https://doi.org/10.1038/s41560-019-0356-8\n",
    "\n",
    "#### Download the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "url = 'https://drive.google.com/uc?export=download&id=1wcf5ctLG8TLnHN4lt3OJSpk5nmZcyY3z'\n",
    "output = 'Standford_Batch1_CH1.h5'\n",
    "gdown.download(url, output, quiet=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the initial modules and the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "fname = 'Standford_Batch1_CH1.h5'\n",
    "df = pd.read_hdf(fname)\n",
    "\n",
    "# print out the column headers\n",
    "print(df.keys())\n",
    "\n",
    "# how many cycles are there?\n",
    "ncycmax = df['Cycle Num'].max()\n",
    "print('\\nnumber of cycles:', ncycmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's plot some quantities we may be interested in\n",
    "Start off with current over the life of the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotting module\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# first plot the current over the entire life of the cell\n",
    "plt.figure(num='current_vs_cycle')\n",
    "plt.plot(df['Test Time (s)'].values, df['Current (Amps)'].values, 'k-')\n",
    "plt.xlabel('Test time (s)')\n",
    "plt.ylabel('Current (Amps)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gosh, that's really not helpful\n",
    "Let's look at cycles 1 through 3 cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = (df['Cycle Num'].values > 0)*(df['Cycle Num'].values < 4)\n",
    "\n",
    "plt.figure(num='current_vs_cycle_try2')\n",
    "plt.plot(df['Test Time (s)'].values[sel], df['Current (Amps)'].values[sel], 'k-')\n",
    "plt.xlabel('Test time (s)')\n",
    "plt.ylabel('Current (Amps)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are we looking at here?\n",
    "* positive current is for charging\n",
    "* negative current is for discharging\n",
    "* zero current is a rest\n",
    "\n",
    "#### On your own, plot the voltage versus time for cycle 1\n",
    "#### Take a few mintues to experiment with plotting other quantities as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### open up this cell if you need a hint\n",
    "<font color='white'>\n",
    "sel = df['Cycle Num'].values == 1\n",
    "plt.figure(num='voltage_cycle_1')\n",
    "plt.plot(df['Test Time (s)'].values[sel], df['Voltage'].values[sel], 'k-')\n",
    "plt.xlabel('Test time (s)')\n",
    "plt.ylabel('Voltage')\n",
    "plt.tight_layout()\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's extract the maximum discharge capacity of the cell throughout its life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycs = np.arange(2, ncycmax)\n",
    "cycs = np.delete(cycs, 10)\n",
    "Qmaxs = []\n",
    "\n",
    "plt.figure(num='discharge capacity vs. cycle')\n",
    "for cyc in cycs:\n",
    "    sel = (df['Cycle Num'].values == cyc)*(df['Current (Amps)'].values < -0.1)\n",
    "    t = df['Test Time (s)'].values[sel]\n",
    "    C = -1*df['Current (Amps)'].values[sel]\n",
    "    dt = np.diff(t)\n",
    "    Cmid = (C[1:] + C[:-1])/(2*3600)\n",
    "    Qmaxs.append(np.sum(dt*Cmid))\n",
    "\n",
    "    plt.plot(t - t.min(), C, 'k-', alpha=0.01)\n",
    "\n",
    "plt.xlabel('Test time (s)')\n",
    "plt.ylabel('Discharge current (Amps)')\n",
    "plt.tight_layout()\n",
    "    \n",
    "plt.figure(num='max capacity vs. cycle')\n",
    "plt.plot(cycs, Qmaxs, 'k-')\n",
    "plt.xlabel('Cycle number')\n",
    "plt.ylabel('Maximum capacity (Amp hrs.)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's extract some features that could help us predict the capacity\n",
    "\n",
    "Also, let's normalize them and plot them versus cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featd = {'mean V':[], 'V integral over time':[]}\n",
    "\n",
    "# calculate features for each cycles\n",
    "for cyc in cycs:\n",
    "    # select the cycle and where the current is negative\n",
    "    sel = (df['Cycle Num'].values == cyc)*(df['Current (Amps)'].values < -0.1)\n",
    "    t = df['Test Time (s)'].values[sel]\n",
    "    C = -1*df['Current (Amps)'].values[sel]\n",
    "    V = df['Voltage'].values[sel]\n",
    "\n",
    "    # calculate features\n",
    "    featd['mean V'].append(V.mean())\n",
    "    dt = np.diff(t)\n",
    "    Vmid = (V[1:] + V[:-1])/2\n",
    "    featd['V integral over time'].append(np.sum(dt*Vmid))\n",
    "    \n",
    "# plot all of the features\n",
    "features = list(featd.keys())\n",
    "colors = sns.color_palette()[:len(features)]\n",
    "\n",
    "plt.figure(num='features vs. cycle')\n",
    "for feature, color in zip(features, colors):\n",
    "    feats = featd[feature]\n",
    "    # normalize the features\n",
    "    feats = (feats - np.mean(feats))/np.std(feats)\n",
    "    plt.plot(cycs, feats, marker='', ls='-',\n",
    "        c=color, alpha=0.9, label=feature)\n",
    "plt.xlabel('Cycle number')\n",
    "plt.ylabel('Normalized feature value')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's evaluate how these features correlate with the SOH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "for feature in features:\n",
    "    r, p = pearsonr(featd[feature], Qmaxs)\n",
    "    print(feature, 'pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "    plt.figure(num=feature + ' correlation')\n",
    "    feats = featd[feature]\n",
    "    plt.plot(Qmaxs, feats, 'k.')\n",
    "    plt.plot([np.min(Qmaxs), np.max(Qmaxs)], [np.min(feats), np.max(feats)], 'k-')\n",
    "    plt.xlabel('Maximum capacity (Amp. hrs.)')\n",
    "    plt.ylabel(feature)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's finally develop a very simple machine learning model\n",
    "\n",
    "The first step is to split our dataset into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert feature dictionary into a Pandas dataframe because it is easier to handle\n",
    "fdf = pd.DataFrame.from_dict(featd)\n",
    "\n",
    "# reserve the last 500 cycles for the test set\n",
    "X_ = fdf.values[:-500, :]\n",
    "y = np.array(Qmaxs)\n",
    "y_ = y[:-500]\n",
    "cycs_ = cycs[:-500]\n",
    "indx = (np.random.random(size=X_.shape[0]) < 0.8)\n",
    "\n",
    "X_train = X_[indx, :]\n",
    "y_train = y_[indx]\n",
    "cycs_train = cycs_[indx]\n",
    "\n",
    "X_validate = X_[np.invert(indx), :]\n",
    "y_validate = y_[np.invert(indx)]\n",
    "cycs_validate = cycs_[np.invert(indx)]\n",
    "\n",
    "X_test = fdf.values[-500:, :]\n",
    "y_test = y[-500:]\n",
    "cycs_test = cycs[-500:]\n",
    "\n",
    "print('X_train.shape :', X_train.shape)\n",
    "print('X_validate.shape :', X_validate.shape)\n",
    "print('X_test.shape :', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a model using linear regression and evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "p_train = lr.predict(X_train)\n",
    "p_validate = lr.predict(X_validate)\n",
    "p_test = lr.predict(X_test)\n",
    "\n",
    "r, p = pearsonr(y_train, p_train)\n",
    "r, p = pearsonr(y_validate, p_validate)\n",
    "\n",
    "r, p = pearsonr(y_train, p_train)\n",
    "print('training pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "r, p = pearsonr(y_validate, p_validate)\n",
    "print('validation pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "r, p = pearsonr(y_test, p_test)\n",
    "print('testing pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "\n",
    "mae = np.mean(100*np.abs(y_train - p_train)/y_train)\n",
    "print('training MAPE:', np.round(mae, 3), '%')\n",
    "mae = np.mean(100*np.abs(y_validate - p_validate)/y_validate)\n",
    "print('validation MAPE:', np.round(mae, 3), '%')\n",
    "mae = np.mean(100*np.abs(y_test - p_test)/y_test)\n",
    "print('testing MAPE:', np.round(mae, 3), '%')\n",
    "\n",
    "plt.figure(num='linear regression SOH prediction')\n",
    "plt.plot(cycs, y, 'g-', label='SOH')\n",
    "plt.plot(cycs_train, p_train, 'k.', alpha=0.5, label='train')\n",
    "plt.plot(cycs_validate, p_validate, 'b.', alpha=0.5, label='validate')\n",
    "plt.plot(cycs_test, p_test, 'r.', alpha=0.5, label='test')\n",
    "plt.xlabel('Cycle number')\n",
    "plt.ylabel('Maximum capacity')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(num='linear regression parity', figsize=(4.5, 4))\n",
    "plt.plot(y_train, p_train, 'k.', alpha=0.5, label='train')\n",
    "plt.plot(y_validate, p_validate, 'b.', alpha=0.5, label='validate')\n",
    "plt.plot(y_test, p_test, 'r.', alpha=0.5, label='test')\n",
    "all_y = list(y_train) + list(p_train) + list(y_validate) + \\\n",
    "    list(p_validate) + list(y_test) + list(p_test)\n",
    "ymin = np.min(all_y)\n",
    "ymax = np.max(all_y)\n",
    "yrng = ymax - ymin\n",
    "spc = 0.1\n",
    "plt.plot([ymin-spc*yrng, ymax+spc*yrng],\n",
    "         [ymin-spc*yrng, ymax+spc*yrng], 'k-')\n",
    "plt.xlabel('experiment')\n",
    "plt.ylabel('prediction')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take 15 or so minutes to experiment with different feature sets and see if you can improve the validation performance. As a hint, look at the voltage and current behavior and see if you can think of features that may correlate well with the SOH.\n",
    "\n",
    "Next, instead of using an analytical least squares regression approach as before, let's manually define our model and optimize the parameters numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "def lin_model(X, params):\n",
    "    p = params[0]*np.ones(X.shape[0])\n",
    "    for ii in range(X.shape[1]):\n",
    "        p += params[ii+1]*X[:, ii]\n",
    "    return p\n",
    "        \n",
    "def cost(X, y, params):\n",
    "    return np.sum((lin_model(X, params) - y)**2)\n",
    "\n",
    "def cost_opt(params):\n",
    "    return cost(X_train, y_train, params)\n",
    "\n",
    "nparam = X_train.shape[1] + 1\n",
    "params0 = np.zeros((nparam,))\n",
    "# res = minimize(cost_opt, params0)\n",
    "bounds = np.zeros((nparam, 2))\n",
    "bounds[:, 0] = -1\n",
    "bounds[:, 1] = 1\n",
    "res = differential_evolution(cost_opt, bounds)\n",
    "print(res)\n",
    "params = res.x\n",
    "\n",
    "p_train = lin_model(X_train, params)\n",
    "p_validate = lin_model(X_validate, params)\n",
    "p_test = lin_model(X_test, params)\n",
    "\n",
    "r, p = pearsonr(y_train, p_train)\n",
    "r, p = pearsonr(y_validate, p_validate)\n",
    "\n",
    "r, p = pearsonr(y_train, p_train)\n",
    "print('training pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "r, p = pearsonr(y_validate, p_validate)\n",
    "print('validation pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "r, p = pearsonr(y_test, p_test)\n",
    "print('testing pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "\n",
    "mae = np.mean(100*np.abs(y_train - p_train)/y_train)\n",
    "print('training MAPE:', np.round(mae, 3), '%')\n",
    "mae = np.mean(100*np.abs(y_validate - p_validate)/y_validate)\n",
    "print('validation MAPE:', np.round(mae, 3), '%')\n",
    "mae = np.mean(100*np.abs(y_test - p_test)/y_test)\n",
    "print('testing MAPE:', np.round(mae, 3), '%')\n",
    "\n",
    "plt.figure(num='linear regression SOH prediction v2')\n",
    "plt.plot(cycs, y, 'g-', label='SOH')\n",
    "plt.plot(cycs_train, p_train, 'k.', alpha=0.5, label='train')\n",
    "plt.plot(cycs_validate, p_validate, 'b.', alpha=0.5, label='validate')\n",
    "plt.plot(cycs_test, p_test, 'r.', alpha=0.5, label='test')\n",
    "plt.xlabel('Cycle number')\n",
    "plt.ylabel('Maximum capacity')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(num='linear regression parity v2', figsize=(4.5, 4))\n",
    "plt.plot(y_train, p_train, 'k.', alpha=0.5, label='train')\n",
    "plt.plot(y_validate, p_validate, 'b.', alpha=0.5, label='validate')\n",
    "plt.plot(y_test, p_test, 'r.', alpha=0.5, label='test')\n",
    "all_y = list(y_train) + list(p_train) + list(y_validate) + \\\n",
    "    list(p_validate) + list(y_test) + list(p_test)\n",
    "ymin = np.min(all_y)\n",
    "ymax = np.max(all_y)\n",
    "yrng = ymax - ymin\n",
    "spc = 0.1\n",
    "plt.plot([ymin-spc*yrng, ymax+spc*yrng],\n",
    "         [ymin-spc*yrng, ymax+spc*yrng], 'k-')\n",
    "plt.xlabel('experiment')\n",
    "plt.ylabel('prediction')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's attempt to do a prediciton with a neural network model. Here we are using a simple framework from scikit-learn, but Tensorflow or PyTorch are much more flexible and powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "nn = MLPRegressor(hidden_layer_sizes=(500,), max_iter=1000).fit(X_train, y_train)\n",
    "p_train = nn.predict(X_train)\n",
    "p_validate = nn.predict(X_validate)\n",
    "p_test = nn.predict(X_test)\n",
    "\n",
    "r, p = pearsonr(y_train, p_train)\n",
    "r, p = pearsonr(y_validate, p_validate)\n",
    "\n",
    "r, p = pearsonr(y_train, p_train)\n",
    "print('training pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "r, p = pearsonr(y_validate, p_validate)\n",
    "print('validation pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "r, p = pearsonr(y_test, p_test)\n",
    "print('testing pearson correlation:', np.round(r, 3), 'and p-value:', np.round(p, 3))\n",
    "\n",
    "mae = np.mean(100*np.abs(y_train - p_train)/y_train)\n",
    "print('training MAPE:', np.round(mae, 3), '%')\n",
    "mae = np.mean(100*np.abs(y_validate - p_validate)/y_validate)\n",
    "print('validation MAPE:', np.round(mae, 3), '%')\n",
    "mae = np.mean(100*np.abs(y_test - p_test)/y_test)\n",
    "print('testing MAPE:', np.round(mae, 3), '%')\n",
    "\n",
    "plt.figure(num='linear regression SOH prediction v3')\n",
    "plt.plot(cycs, y, 'g-', label='SOH')\n",
    "plt.plot(cycs_train, p_train, 'k.', alpha=0.5, label='train')\n",
    "plt.plot(cycs_validate, p_validate, 'b.', alpha=0.5, label='validate')\n",
    "plt.plot(cycs_test, p_test, 'r.', alpha=0.5, label='test')\n",
    "plt.xlabel('Cycle number')\n",
    "plt.ylabel('Maximum capacity')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(num='linear regression parity v3', figsize=(4.5, 4))\n",
    "plt.plot(y_train, p_train, 'k.', alpha=0.5, label='train')\n",
    "plt.plot(y_validate, p_validate, 'b.', alpha=0.5, label='validate')\n",
    "plt.plot(y_test, p_test, 'r.', alpha=0.5, label='test')\n",
    "all_y = list(y_train) + list(p_train) + list(y_validate) + \\\n",
    "    list(p_validate) + list(y_test) + list(p_test)\n",
    "ymin = np.min(all_y)\n",
    "ymax = np.max(all_y)\n",
    "yrng = ymax - ymin\n",
    "spc = 0.1\n",
    "plt.plot([ymin-spc*yrng, ymax+spc*yrng],\n",
    "         [ymin-spc*yrng, ymax+spc*yrng], 'k-')\n",
    "plt.xlabel('experiment')\n",
    "plt.ylabel('prediction')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
